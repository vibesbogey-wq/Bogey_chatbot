import os
import streamlit as st
from pinecone import Pinecone
from openai import OpenAI

# --- ENV ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY", "").strip()
INDEX_NAME = os.getenv("PINECONE_INDEX", "rag-chat-demo").strip()

if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY missing")
if not PINECONE_API_KEY:
    raise ValueError("PINECONE_API_KEY missing")

client = OpenAI(api_key=OPENAI_API_KEY)
pc = Pinecone(api_key=PINECONE_API_KEY)
index = pc.Index(INDEX_NAME)   # ‚úÖ host-–≥“Ø–π

# ---------- Embedding ----------
def embed_text(text: str):
    res = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return res.data[0].embedding

# ---------- Query Rewriter ----------
def rewrite_query(question: str) -> str:
    """
    –•—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω –∞—Å—É—É–ª—Ç—ã–≥ vector search-–¥ –∏–ª“Ø“Ø —Ç–æ—Ö–∏—Ä–æ–º–∂—Ç–æ–π –±–æ–ª–≥–æ–∂ ”©”©—Ä—á–∏–ª–Ω”©.
    """
    prompt = f"""
–ß–∏ Ecommerce + Kids clothing catalog –¥—ç—ç—Ä —Ö–∞–π–ª—Ç —Ö–∏–π—Ö —Ç—É—Å–ª–∞—Ö.

–•—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω –∞—Å—É—É–ª—Ç—ã–≥ Pinecone vector search-–¥ —Ö–∞–º–≥–∏–π–Ω —Ç–æ—Ö–∏—Ä–æ–º–∂—Ç–æ–π —Ö–∞–π–ª—Ç—ã–Ω query –±–æ–ª–≥–æ–Ω ”©”©—Ä—á–∏–ª.
- –ê–Ω–≥–ª–∏ —Ö—ç–ª—ç—ç—Ä –±–∏—á.
- –ë–æ–ª–æ–º–∂—Ç–æ–π –±–æ–ª gender (boys/girls/unisex), product type, size/age range, material, season –∑—ç—Ä–≥–∏–π–≥ —Ç–∞–∞–º–∞–≥–ª–∞–Ω –Ω—ç–º.
- –•—ç—Ç —É—Ä—Ç –±–æ–ª–≥–æ—Ö–≥“Ø–π, 1 ”©–≥“Ø“Ø–ª–±—ç—Ä –±–∞–π—Ö–∞–¥ —Ö–∞–Ω–≥–∞–ª—Ç—Ç–∞–π.

–ñ–∏—à—ç—ç:
"11 –Ω–∞—Å—Ç–∞–π —Ö“Ø“Ø" -> "boys clothing size 140 age 10-12"
"–æ—Ö–∏–¥—ã–Ω –¥–∞–∞—à–∏–Ω–∑" -> "girls dress cotton size 120-150"
"”©–≤–ª–∏–π–Ω –∫—É—Ä—Ç–∏–∫" -> "kids winter jacket warm size 130-150"

Original: {question}
Rewritten:
"""
    try:
        res = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0,
        )
        return res.choices[0].message.content.strip()
    except Exception:
        # rewrite –∞–ª–¥–∞–∞ –≥–∞—Ä–≤–∞–ª original-–æ–æ –∞—à–∏–≥–ª–∞–Ω–∞
        return question

# ---------- Context Cleaner ----------
def clean_context(text: str) -> str:
    """
    –î–∞–≤—Ö–∞—Ä–¥—Å–∞–Ω –º”©—Ä/—Ö–æ–æ—Å–æ–Ω –∑–∞–π –∞—Ä–∏–ª–≥–∞–∂, GPT-–¥ —Ü—ç–≤—ç—Ä context ”©–≥–Ω”©.
    """
    lines = [ln.strip() for ln in text.split("\n") if ln.strip()]
    # –¥–∞–≤—Ö–∞—Ä–¥–ª—ã–≥ –∞—Ä–∏–ª–≥–∞–Ω–∞
    uniq = []
    seen = set()
    for ln in lines:
        if ln not in seen:
            uniq.append(ln)
            seen.add(ln)
    return "\n".join(uniq)

# ---------- Retrieval (Hybrid) ----------
def retrieve_context(query: str, top_k: int = 5):
    """
    Original query + rewritten query 2-–æ–æ—Ä —Ö–∞–π–∂ context-–æ–æ –±–∞—è–∂—É—É–ª–Ω–∞.
    """
    rewritten = rewrite_query(query)

    vectors = []
    for q in [query, rewritten]:
        try:
            q_vec = embed_text(q)
            res = index.query(vector=q_vec, top_k=top_k, include_metadata=True)
            for m in res.matches:
                t = m.metadata.get("text", "")
                if t:
                    vectors.append(t)
        except Exception as e:
            st.error(f"Pinecone query error: {e}")
            return ""

    return clean_context("\n\n".join(vectors))

# ---------- Answer Generation ----------
def generate_answer(question: str, context: str) -> str:
    system_prompt = (
        "–ß–∏ –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—Ç—ç–π —É—Ö–∞–∞–ª–∞–≥ —Ç—É—Å–ª–∞—Ö. "
        "–î–æ–æ—Ä—Ö CONTEXT –±–æ–ª –º–∞–Ω–∞–π –º—ç–¥–ª—ç–≥–∏–π–Ω —Å–∞–Ω (CSV + PDF). "
        "–ó”©–≤—Ö”©–Ω CONTEXT –¥—ç—ç—Ä “Ø–Ω–¥—ç—Å–ª—ç–∂ —Ö–∞—Ä–∏—É–ª. "
        "CONTEXT —Ö–∞–Ω–≥–∞–ª—Ç–≥“Ø–π –±–æ–ª '–ú—ç–¥—ç—ç–ª—ç–ª –º–∞–Ω–∞–π –º—ç–¥–ª—ç–≥–∏–π–Ω —Å–∞–Ω–¥ –∞–ª–≥–∞ –±–∞–π–Ω–∞' –≥—ç–∂ —Ö—ç–ª. "
        "–•–∞—Ä–∏—É–ª—Ç–∞–∞ —Ç–æ–≤—á, –æ–π–ª–≥–æ–º–∂—Ç–æ–π, —Ö—ç—Ä—ç–≥—Ç—ç–π –∑”©–≤–ª”©–≥”©”©—Ç—ç–π ”©–≥."
    )

    user_content = f"""
CONTEXT:
{context}

QUESTION:
{question}

INSTRUCTIONS:
1) –≠—Ö–ª—ç—ç–¥ CONTEXT-—Å —Ö–∞–º–∞–∞—Ä–∞—Ö —Ö—ç—Å–≥–∏–π–≥ –æ–ª.
2) –î–∞—Ä–∞–∞ –Ω—å —Ö—ç—Ä—ç–≥–ª—ç–≥—á–∏–¥ –æ–π–ª–≥–æ–º–∂—Ç–æ–π –º–æ–Ω–≥–æ–ª–æ–æ—Ä —Ö–∞—Ä–∏—É–ª.
3) CONTEXT-–¥ –±–∞–π—Ö–≥“Ø–π –∑“Ø–π–ª–∏–π–≥ –±“Ø“Ø –∑–æ—Ö–∏–æ–∂ —Ö—ç–ª.
"""

    res = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content},
        ],
        temperature=0.2,
    )
    return res.choices[0].message.content

# ---------- UI ----------
st.set_page_config(page_title="RAG Chatbot", layout="centered")
st.title("ü§ñ FIVEBABY –¥—ç–ª–≥“Ø“Ø—Ä–∏–π–Ω Chatbot (Smarter RAG")
st.caption("CSV + PDF –º—ç–¥–ª—ç–≥ –¥—ç—ç—Ä “Ø–Ω–¥—ç—Å–ª—ç–Ω Bolortsoojin —É—Ö–∞–∞–ª–∞–≥ —Ö–∞–π–ª—Ç —Ö–∏–π–∂ —Ö–∞—Ä–∏—É–ª–¥–∞–≥ —á–∞—Ç.")

bubble_css = """
<style>
.chat-container { width: 100%; margin-top: 8px; }
.user-bubble {
    background-color: #2b2b2b; color: white; padding: 12px 16px;
    border-radius: 16px; border-bottom-right-radius: 4px;
    max-width: 70%; float: right; margin: 6px 0; font-size: 16px;
}
.bot-bubble {
    background-color: #ffe082; color: black; padding: 12px 16px;
    border-radius: 16px; border-bottom-left-radius: 4px;
    max-width: 70%; float: left; margin: 6px 0; font-size: 16px;
}
.clearfix { clear: both; }
</style>
"""
st.markdown(bubble_css, unsafe_allow_html=True)

if "messages" not in st.session_state:
    st.session_state["messages"] = []

for msg in st.session_state["messages"]:
    if msg["role"] == "user":
        st.markdown(
            f"<div class='chat-container'><div class='user-bubble'>{msg['content']}</div><div class='clearfix'></div></div>",
            unsafe_allow_html=True,
        )
    else:
        st.markdown(
            f"<div class='chat-container'><div class='bot-bubble'>{msg['content']}</div><div class='clearfix'></div></div>",
            unsafe_allow_html=True,
        )

user_input = st.chat_input("–ê—Å—É—É—Ö –∑“Ø–π–ª—ç—ç –±–∏—á—ç—ç—Ä—ç–π...")

if user_input:
    st.session_state["messages"].append({"role": "user", "content": user_input})
    st.markdown(
        f"<div class='chat-container'><div class='user-bubble'>{user_input}</div><div class='clearfix'></div></div>",
        unsafe_allow_html=True,
    )

    context = retrieve_context(user_input, top_k=6)
    answer = generate_answer(user_input, context)

    st.markdown(
        f"<div class='chat-container'><div class='bot-bubble'>{answer}</div><div class='clearfix'></div></div>",
        unsafe_allow_html=True,
    )
    st.session_state["messages"].append({"role": "assistant", "content": answer})
